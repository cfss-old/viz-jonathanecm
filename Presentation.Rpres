Popular Twits in The Middle of a Political Crisis
========================================================
author: Camacho Jonathan
date: 05/31/2017
autosize: true

Question:
========================================================

- In the middle of the current political crisis, what are the charactetistics of the most Venezuela's most popular tweets?

Context:
========================================================

Methods:
========================================================
- Created a API to get tweets from 05/01 to 05/28.
       - Initial size: 45,000 tweets.
- Tidy dataset
       - Romoved retweets.
       - Tokenized tweets by words and ngrams.
       - Added new variables: tweet type, and tweet popularity.
- Final size: 6,445 tweets. 

Frequency Analysis
========================================================

```{r, echo=FALSE, message= FALSE}
library(tidytext)
library(stringr)
library(knitr)
library(readr)
library(tidyverse)
library(ggplot2)
library(scales)
```
```{r, echo=FALSE, echo=FALSE, message=FALSE}
# Variables
set.seed(1234)
theme_set(theme_minimal())
reg <- "([^A-Za-z\\d#@']|'(?![A-Za-z\\d#@]))"
spanish_stopwords <- read_csv("./data/stopwords_es.csv")
```


```{r, echo=FALSE, message=FALSE}
# Reading data. 
all_tweets <- as.tibble(read_csv("./data/all_tweets.csv"))
```

```{r, echo=FALSE, message=FALSE}
# Tokenizing by one term. 
one_term <- all_tweets %>%
       mutate(popularity = ifelse(retweetCount %in% 0:20, "low",
                                  ifelse(retweetCount %in% 21:200, "medium", "high"))) %>% 
       mutate(text = str_replace_all(text, c("https://t.co/[A-Za-z\\d]+|&amp;"), "")) %>%
       unnest_tokens(word, text, token = "regex", pattern = reg, drop = FALSE) %>%
       filter(!word %in% spanish_stopwords$Word, str_detect(word, "[a-z]"))
```

```{r, echo=FALSE, message=FALSE, fig.align}
# Count by twit popularity.
total_words_popularity <- as.tibble(table(one_term$popularity))
kable(total_words_popularity, col.names = c("Populatiry", "Total"), caption = "Terms' Frecuency.")
```

Terms' Frequency.
========================================================
```{r, echo=FALSE, message=FALSE}
# Words frecuency.
one_term %>%
  count(word, sort = TRUE) %>%
  filter(n > 200) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  labs(title = "Frecuency of Terms",
       x = "Frecuency", y = "Terms") +
  coord_flip()
```

Terms's tf_idf Frequency.
========================================================
```{r, echo=FALSE, message = FALSE}
# tf_idf Frequencies
tweet_words_count <- one_term %>%
  count(popularity, word, sort = TRUE) %>%
  ungroup()

total_words <- tweet_words_count %>%
  group_by(popularity) %>%
  summarize(total = sum(n))

tweet_words_count <- left_join(tweet_words_count, total_words)

tweet_words_count <- tweet_words_count %>%
  bind_tf_idf(word, popularity, n)

tweet_words_coun <- tweet_words_count %>%
  select(-total) %>%
  arrange(desc(tf_idf))

tweet_important <- tweet_words_count %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word))))

tweet_important %>%
  top_n(35) %>%
  ggplot(aes(word, tf_idf, fill = popularity)) +
  geom_col() +
  labs(title = "Highest tf-idf words by Popularity",
       x = "Word", y = "tf-idf") +
  coord_flip()
```
One-grams' tf_idf Frequency.
========================================================
```{r, echo=FALSE}
tweet_important %>%
  top_n(25) %>%
  ggplot(aes(word, tf_idf, fill = popularity)) +
  geom_col() +
  labs(title = "Highest tf-idf words by Popularity",
       x = "Word", y = "tf-idf") +
  coord_flip() + 
       facet_wrap(~ popularity, ncol = 2, scales = "free_y")
```
N-grams' Frecuency
========================================================
```{r, echo=FALSE, message=FALSE}
ngrams <- all_tweets %>%
       mutate(popularity = ifelse(retweetCount %in% 0:20, "low",
                                  ifelse(retweetCount %in% 21:200, "medium", "high"))) %>% 
       mutate(text = str_replace_all(text, c("https://t.co/[A-Za-z\\d]+|&amp;"), "")) %>%
       unnest_tokens(trigram, text, token = "ngrams", n = 3) %>%
       separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
       filter(!word1 %in% spanish_stopwords$Word, str_detect(word1, "[a-z]"), 
              !word2 %in% spanish_stopwords$Word, str_detect(word2, "[a-z]"),
              !word3 %in% spanish_stopwords$Word, str_detect(word3, "[a-z]"))
```

```{r, echo=FALSE, message=FALSE}
ngrams %>% 
       count(word1, word2, word3, sort = TRUE) %>% 
       head() %>%
       kable(col.names = c("Word 1", "Word 2", "word 3", "Total"),  caption = "nGrams' Frecuency.")
```
T
========================================================
```{r, echo=FALSE, message=FALSE}
ngrams_united <- ngrams %>%
  unite(ngram, word1, word2, word3, sep = " ")

ngram_tf_idf <- ngrams_united %>%
  count(popularity, ngram) %>%
  bind_tf_idf(ngram, popularity, n) %>%
  arrange(desc(tf_idf))
```

```{r, echo=FALSE, message=FALSE}
ngram_tf_idf %>%
  top_n(5) %>%
  ggplot(aes(ngram, tf_idf, fill = popularity)) +
  geom_col(alpha = 0.8) +
  labs(title = "N-grams Ranked by tf-idf and Group by Popularity",
       x = "Word", y = "tf-idf") +
  coord_flip() + 
       facet_wrap(~ popularity, ncol = 1, scales = "free_y")
```